#!/bin/bash

# Manual deployment steps for enhanced scraper
# Run each section manually to ensure success

echo "Enhanced Scraper Manual Deployment Steps"
echo "========================================"
echo ""
echo "Run these commands one by one:"
echo ""

# Step 1: Create remote directory
echo "# Step 1: Create deployment directory on server"
echo "ssh ubuntu@54.213.98.235 'mkdir -p /tmp/enhanced-deploy'"
echo ""

# Step 2: Copy files
echo "# Step 2: Copy scraper files"
echo "scp scrapers/nvrcEnhancedDetailScraper.js ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo "scp import-enhanced-activities.js ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo "scp scripts/run-enhanced-scraper.sh ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo "scp scripts/setup-scraper-cron.sh ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo ""

# Step 3: Copy schema files
echo "# Step 3: Copy database schema"
echo "scp prisma/schema.prisma ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo "ssh ubuntu@54.213.98.235 'mkdir -p /tmp/enhanced-deploy/migrations'"
echo "scp prisma/migrations/add_activity_details/migration.sql ubuntu@54.213.98.235:/tmp/enhanced-deploy/migrations/"
echo ""

# Step 4: Copy updated service
echo "# Step 4: Copy updated activity service"
echo "scp src/services/activityService.enhanced.updated.ts ubuntu@54.213.98.235:/tmp/enhanced-deploy/"
echo ""

# Step 5: SSH and install
echo "# Step 5: SSH to server and install"
echo "ssh ubuntu@54.213.98.235"
echo ""
echo "# Once connected, run these commands:"
echo "cd /home/ubuntu/KidsActivityTracker/backend"
echo ""
echo "# Backup current files"
echo "cp prisma/schema.prisma prisma/schema.prisma.backup-$(date +%Y%m%d-%H%M%S)"
echo "cp src/services/activityService.enhanced.ts src/services/activityService.enhanced.ts.backup"
echo ""
echo "# Copy new files"
echo "cp /tmp/enhanced-deploy/nvrcEnhancedDetailScraper.js scrapers/"
echo "cp /tmp/enhanced-deploy/import-enhanced-activities.js ."
echo "cp /tmp/enhanced-deploy/run-enhanced-scraper.sh scripts/"
echo "cp /tmp/enhanced-deploy/setup-scraper-cron.sh scripts/"
echo "cp /tmp/enhanced-deploy/schema.prisma prisma/"
echo "cp /tmp/enhanced-deploy/activityService.enhanced.updated.ts src/services/activityService.enhanced.ts"
echo ""
echo "# Create migration directory and copy migration"
echo "mkdir -p prisma/migrations/20250809_add_activity_details"
echo "cp /tmp/enhanced-deploy/migrations/migration.sql prisma/migrations/20250809_add_activity_details/"
echo ""
echo "# Make scripts executable"
echo "chmod +x scripts/run-enhanced-scraper.sh"
echo "chmod +x scripts/setup-scraper-cron.sh"
echo ""
echo "# Install dependencies and run migrations"
echo "npm install"
echo "npx prisma migrate deploy"
echo "npx prisma generate"
echo ""
echo "# Create necessary directories"
echo "mkdir -p logs data/archive"
echo ""
echo "# Restart the API service to load new code"
echo "pm2 restart kids-backend"
echo ""
echo "# Run the enhanced scraper (this will take 15-20 minutes)"
echo "./scripts/run-enhanced-scraper.sh"
echo ""
echo "# Verify data in database"
echo "psql \$DATABASE_URL -c \"SELECT COUNT(*) FROM \\\"Activity\\\" WHERE \\\"registrationStatus\\\" IS NOT NULL;\""
echo ""
echo "# Setup cron for daily updates"
echo "./scripts/setup-scraper-cron.sh"
echo ""
echo "# Test API endpoint"
echo "curl -s 'http://localhost:3001/api/activities?limit=1' | jq '.activities[0] | {name, registrationStatus, fullDescription}'"